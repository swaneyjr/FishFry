#!/usr/bin/env python3

import os

import ROOT as r
import numpy as np
import matplotlib.pyplot as plt

if __name__ == '__main__':
    from argparse import ArgumentParser
    parser = ArgumentParser(description='')
    parser.add_argument('pfile', nargs='+', help='ROOT file generated by mark_triggered.py')
    parser.add_argument('--calib', default='calib', help='path to calibration directory')
    parser.add_argument('--thresh', type=int, default=0, help='Additional threshold')
    parser.add_argument('--log', action='store_true', help='Display a logscale for y')
    parser.add_argument('--bin_sz', type=int, default=16, help='Bin width for plots')
    args = parser.parse_args() 
     
    # first load calibration data
    try:
        f_acc = np.load(os.path.join(args.calib, 'acceptance.npz'))
        
        # P(hodoscope | phone)
        p_hgp = f_acc['p_hgp']
        p_hgp_err = f_acc['p_hgp_err']
        
        # P(phone | hodoscope)
        p_pgh = f_acc['p_pgh']
        p_pgh_err = f_acc['p_pgh_err']

        # in Hz
        expected_rate = f_acc['rate']

        f_acc.close()
    except:
        print('ERROR: Acceptance not found. Try running "acceptance.py" first')
        exit(1)

    sat_min = 1023
    gmin = 0
    blk_lvl = 0
    try:
        f_wgt = np.load(os.path.join(args.calib, 'lens.npz'))
        lens = f_wgt['lens']
        wgt = np.where(lens > 0, 1/lens, 0)
        wgt /= wgt.max()
        sat_min = int(sat_min * wgt.min())

        gmin = lens.min()

        if 'blk_lvl' in f_wgt.files:
            blk_lvl = f_wgt['blk_lvl']

        f_wgt.close()

    except FileNotFoundError:
        print('Weights not found.  Using equal weights.')


    # now look through ROOT files

    # in order to avoid artificial caps, we restrict the range
    # to the minimum weighted saturation value
    
    bins = np.arange(0, 1025, args.bin_sz)
    bin_min_all = 0
    bin_max_all = (sat_min//args.bin_sz) + 2
    cdf_vals = []
    cdf_errs = []

    for pf in args.pfile:
        print(pf)
        tag = []
        tot = []

        pfile = r.TFile(pf)
        ptree = pfile.Get('triggers')
    
        bnames = [b.GetName() for b in ptree.GetListOfBranches()]
        if not 'tag' in bnames:
            print("ERROR: use mark_triggered.py first")
            exit(1)

        uinfo = ptree.GetUserInfo()
        tolerance = n_hodo = t_tot = t_frame = None

        for param in uinfo:
            if param.GetName() == 'tolerance':
                tolerance = param.GetVal()
            if param.GetName() == 'n_hodo':
                n_hodo = param.GetVal()
            if param.GetName() == 't_tot':
                t_tot = param.GetVal()
            if param.GetName() == 't_frame':
                t_frame = param.GetVal()

        if not tolerance or not n_hodo or not t_tot:
            print("ERROR: Metadata not found")
            exit(1)
        
        vmin = 1024 # this could probably just be saved from thresholds  

        # find ratio of triggered / total
        for evt in ptree:
            cmax = max(evt.cal)
            vmin = min(vmin, cmax)
            if cmax > args.thresh:
                tot.append(cmax)
                if evt.tag:
                    tag.append(cmax)
        
        print("Triggered: {} / {}".format(len(tag), len(tot)))

        hodo_rate = (n_hodo - 1) / t_tot * 1e3 # in Hz
        hodo_rate_err = np.sqrt(n_hodo - 1) / t_tot * 1e3
        
        print(u'observed rate: {:.3f} \u00B1 {:.3f} mHz'.format(hodo_rate * 1e3, hodo_rate_err * 1e3))
        print('expected rate: {:.3f} mHz'.format(expected_rate * 1e3))
 
        tag_hist, bins = np.histogram(tag, bins)
        tot_hist, bins = np.histogram(tot, bins)

        tag_hist_cum = np.cumsum(tag_hist[::-1]).astype(float)[::-1]
        tot_hist_cum = np.cumsum(tot_hist[::-1]).astype(float)[::-1]

        # use poisson statistics to estimate total number of hits
        # from triggered frames

        # P(frame occupied) = 1-e^-(lambda*t)
        n_frames = t_tot / t_frame + 1
        
        p_tot = tot_hist_cum / n_frames
        tot_hist_corr = -np.log(1-p_tot) * n_frames
        #tot_hist_err = np.sqrt(tot_hist_cum)/(1-p_tot) 

        untagged = n_frames - tag_hist_cum
        tag_hist_corr = tot_hist_corr + untagged * np.log(1 - (tot_hist_cum - tag_hist_cum) / untagged)
        untag_hist_corr = tot_hist_corr - tag_hist_corr

        print('Max trig rate: {:.2f}'.format(tot_hist_corr[0] / n_frames))



        # calculate and plot signal-to-noise ratio

        hodo_factor = np.exp(tolerance * hodo_rate * 1e-3) 

        cdf = (tag_hist_corr * hodo_factor - tot_hist_corr * (hodo_factor - 1)) / n_hodo / p_pgh
        cdf_var = (cdf * p_pgh_err / p_pgh)**2 \
                + (tot_hist_corr - untag_hist_corr * (1 - tolerance*hodo_rate*1e-3) * hodo_factor)**2 / p_pgh**2 / n_hodo**3 \
                + (p_pgh * n_hodo)**-2 * (tag_hist_corr + untag_hist_corr*(hodo_factor-1)**2)

        cdf_vals.append(cdf)
        cdf_errs.append(np.sqrt(cdf_var)) 

        frac = cdf * n_hodo / tot_hist_corr
        frac_var = (frac * p_pgh_err / p_pgh)**2 \
                + ((tot_hist_corr - tag_hist_corr) * hodo_factor / tag_hist_corr / p_pgh * hodo_rate * tolerance * 1e-3)**2 / n_hodo \
                + ((hodo_factor-1) / p_pgh)**2 * (untag_hist_corr / tag_hist_corr**2 + untag_hist_corr**2 / untag_hist_corr**3)

        snr = (1/frac-1)**-1
        snr_err = np.sqrt(frac_var)/(1-frac)**2

        vmin = max(vmin, args.thresh+1)
        bin_min = vmin // args.bin_sz
        bin_min_all = max(bin_min, bin_min_all)

        plt.figure(figsize=(6.4, 5.6)) 
        ax = plt.gca()
        ax.plot(bins[bin_min+1:bin_max_all+1], snr[bin_min:bin_max_all], 'r-')
        ax.fill_between(bins[bin_min+1:bin_max_all+1], (snr-snr_err)[bin_min:bin_max_all], (snr+snr_err)[bin_min:bin_max_all], color='red', alpha=0.2)

        #ax.errorbar(bins[bin_min+1:bin_max_all+1], snr[bin_min:bin_max_all], yerr=snr_err[bin_min:bin_max_all], fmt='ro')
        if args.log:
            ax.semilogy()
        ax.set_xlabel('Calibrated ADC counts')
        ax.set_ylabel('signal / noise')
        ax.set_title('Integrated signal-to-noise ratio by max values')
        
        if gmin:
            ax2 = ax.twiny()
            ax2.set_xlim(*((np.array(ax.get_xlim()) - blk_lvl) / gmin))
            ax2.set_xlabel('Electrons')
            ax2.xaxis.set_ticks_position('bottom')
            ax2.xaxis.set_label_position('bottom')
            ax2.spines['bottom'].set_position(('outward', 36))

        plt.tight_layout() 
        
        print()

    cdf_combined = np.average(cdf_vals, axis=0, weights=1/np.square(cdf_errs))
    cdf_err_combined = 1/np.sqrt(np.sum(1/np.square(cdf_errs), axis=0))

    eff = cdf_combined[0]
    eff_err = cdf_err_combined[0]

    print(u'eff = {0:.4f} \u00B1 {1:.4f}'.format(eff, eff_err))
  
    plt.figure(figsize=(6.4, 5.6))
    ax = plt.gca()
    ax.plot(bins[bin_min+1:bin_max_all+1], cdf_combined[bin_min:bin_max_all], 'b-')
    ax.fill_between(bins[bin_min+1:bin_max_all+1], (cdf_combined-cdf_err_combined)[bin_min:bin_max_all], (cdf_combined+cdf_err_combined)[bin_min:bin_max_all], alpha=0.2)
    if args.log:
        ax.semilogy()
    ax.set_xlabel('Calibrated ADC counts')
    ax.set_ylabel('Probability')
    ax.set_title('Hit cdf by max values')

    if gmin:
        ax2 = ax.twiny()
        ax2.set_xlim(*(np.array(ax.get_xlim()) / gmin))
        ax2.set_xlabel('Electrons')
        ax2.xaxis.set_ticks_position('bottom')
        ax2.xaxis.set_label_position('bottom')
        ax2.spines['bottom'].set_position(('outward', 36))

    plt.tight_layout()

    plt.show()
